# CI/CD Pipeline for Lambda Performance Testing Application
# Enterprise-grade continuous integration with comprehensive testing

name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop, 'feature/*', 'hotfix/*' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly performance tests
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18.x'
  PERFORMANCE_TEST_DURATION: '300000' # 5 minutes for CI
  COVERAGE_THRESHOLD: '95'

jobs:
  # Quality Gates - Fast feedback
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Lint code
        run: npm run lint

      - name: Type check
        run: npm run type-check

      - name: Security audit
        run: npm audit --audit-level=high
        continue-on-error: true

      - name: Check for outdated dependencies
        run: npm outdated --depth=0
        continue-on-error: true

  # Unit Tests - Core functionality validation
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: quality-gates

    strategy:
      matrix:
        node-version: [18.x, 20.x]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:unit -- --ci --coverage --watchAll=false
        env:
          NODE_ENV: test

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-node-${{ matrix.node-version }}
          path: |
            coverage/
            jest-results.xml
          retention-days: 7

      - name: Validate coverage thresholds
        run: |
          COVERAGE=$(node -e "console.log(JSON.parse(require('fs').readFileSync('coverage/coverage-summary.json')).total.lines.pct)")
          echo "Coverage: $COVERAGE%"
          if (( $(echo "$COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
            echo "Coverage $COVERAGE% is below threshold $COVERAGE_THRESHOLD%"
            exit 1
          fi

  # Integration Tests - API and system integration
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: quality-gates

    services:
      # Add any required services (e.g., Redis, databases)
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Start test server
        run: |
          npm start &
          sleep 10
          curl -f http://localhost:3000/health || exit 1
        env:
          NODE_ENV: test
          PORT: 3000

      - name: Run integration tests
        run: npm run test:integration -- --ci --coverage --watchAll=false
        env:
          NODE_ENV: test
          BASE_URL: http://localhost:3000
          API_KEY: test-api-key

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            coverage/
            integration-test-results.xml
          retention-days: 7

      - name: Generate integration test report
        if: always()
        run: |
          echo "## Integration Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "Tests completed at $(date)" >> $GITHUB_STEP_SUMMARY
          if [ -f "integration-test-results.xml" ]; then
            echo "Test results uploaded as artifact" >> $GITHUB_STEP_SUMMARY
          fi

  # Performance Tests - Load and stress testing
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [unit-tests, integration-tests]
    if: github.event_name != 'pull_request' || contains(github.event.pull_request.labels.*.name, 'performance-test')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Install Artillery
        run: npm install -g artillery@latest

      - name: Build and start application
        run: |
          npm run build
          npm start &
          sleep 15
          curl -f http://localhost:3000/health || exit 1
        env:
          NODE_ENV: production
          PORT: 3000

      - name: Run Jest performance tests
        run: npm run test:performance -- --ci --watchAll=false --testTimeout=600000
        env:
          NODE_ENV: test
          BASE_URL: http://localhost:3000
          PERFORMANCE_TEST_DURATION: ${{ env.PERFORMANCE_TEST_DURATION }}

      - name: Run k6 load tests
        run: |
          export BASE_URL=http://localhost:3000
          k6 run --duration=2m --vus=20 tests/load/k6-scenarios.js
        continue-on-error: true

      - name: Run Artillery load tests
        run: |
          artillery run tests/load/scenarios.yml --output artillery-report.json
          artillery report artillery-report.json --output artillery-report.html
        continue-on-error: true

      - name: Upload performance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: |
            artillery-report.html
            artillery-report.json
            k6-report.html
            performance-test-results.xml
          retention-days: 30

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let comment = '## Performance Test Results\n\n';
            comment += '✅ Performance tests completed successfully\n\n';
            comment += '### Test Summary\n';
            comment += `- **Duration**: ${process.env.PERFORMANCE_TEST_DURATION}ms\n`;
            comment += `- **Date**: ${new Date().toISOString()}\n\n`;
            comment += '### Reports\n';
            comment += '- Artillery report available in artifacts\n';
            comment += '- k6 report available in artifacts\n\n';
            comment += '> Performance test artifacts will be available for 30 days.';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Security Tests - Vulnerability scanning
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: quality-gates

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security audit
        run: npm audit --audit-level=moderate --json > audit-results.json
        continue-on-error: true

      - name: Run SAST with CodeQL
        uses: github/codeql-action/analyze@v3
        with:
          languages: typescript

      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: audit-results.json
          retention-days: 30

  # Build and Package
  build:
    name: Build and Package
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [unit-tests, integration-tests, security-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Create deployment package
        run: |
          mkdir -p dist/package
          cp -r dist/src/* dist/package/
          cp package.json package-lock.json dist/package/
          cd dist/package && npm ci --only=production
          tar -czf ../lambda-performance-app.tar.gz -C . .

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            dist/lambda-performance-app.tar.gz
            dist/src/
          retention-days: 30

  # Deployment (example for staging)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [build, performance-tests]
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: ./dist

      - name: Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # Add your deployment commands here
          # Examples:
          # - AWS Lambda deployment
          # - Docker container deployment
          # - Kubernetes deployment
          echo "Deployment completed"

      - name: Run staging smoke tests
        run: |
          echo "Running staging smoke tests..."
          # Add smoke test commands here
          curl -f ${{ secrets.STAGING_URL }}/health || exit 1

  # Nightly Performance Regression Tests
  nightly-performance:
    name: Nightly Performance Regression
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install performance tools
        run: |
          npm install -g artillery@latest clinic autocannon

      - name: Build and start application
        run: |
          npm run build
          npm start &
          sleep 15
          curl -f http://localhost:3000/health || exit 1
        env:
          NODE_ENV: production
          PORT: 3000

      - name: Run extended performance tests
        run: |
          # Extended k6 tests (30 minutes)
          export BASE_URL=http://localhost:3000
          k6 run --duration=30m --vus=50 tests/load/k6-scenarios.js --summary-export=k6-extended-results.json

          # Extended Artillery tests
          artillery run tests/load/scenarios.yml --duration=1800 --output artillery-extended.json

          # CPU and memory profiling
          npm run perf:profile &
          PROFILE_PID=$!
          sleep 600  # 10 minutes
          kill $PROFILE_PID

      - name: Upload nightly performance results
        uses: actions/upload-artifact@v4
        with:
          name: nightly-performance-results-${{ github.run_number }}
          path: |
            k6-extended-results.json
            artillery-extended.json
            .clinic/
          retention-days: 90

      - name: Create performance regression report
        run: |
          echo "## Nightly Performance Report" > performance-report.md
          echo "**Date**: $(date -u)" >> performance-report.md
          echo "**Commit**: ${{ github.sha }}" >> performance-report.md
          echo "" >> performance-report.md

          # Add performance metrics analysis here
          echo "Performance test results uploaded as artifacts." >> performance-report.md

      - name: Create GitHub issue for performance regression
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const title = `Performance Regression Detected - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## Performance Regression Alert

            **Commit**: ${context.sha}
            **Workflow Run**: ${context.runId}
            **Date**: ${new Date().toISOString()}

            Performance tests failed during nightly regression testing.

            ### Action Required
            - [ ] Review performance test results in artifacts
            - [ ] Analyze performance regression causes
            - [ ] Create fix for performance issues
            - [ ] Re-run performance tests to validate fix

            ### Artifacts
            Performance test artifacts are available in workflow run ${context.runId}.
            `;

            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['performance', 'regression', 'priority-high']
            });

  # Test Results Summary
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [unit-tests, integration-tests, security-tests, performance-tests]

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Generate test summary
        run: |
          echo "# Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status | Artifacts |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|-----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} | unit-test-results |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} | integration-test-results |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Tests | ${{ needs.security-tests.result == 'success' && '✅ Passed' || '❌ Failed' }} | security-scan-results |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Tests | ${{ needs.performance-tests.result == 'success' && '✅ Passed' || needs.performance-tests.result == 'skipped' && '⏭️ Skipped' || '❌ Failed' }} | performance-test-results |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Execution Time**: $(date)" >> $GITHUB_STEP_SUMMARY